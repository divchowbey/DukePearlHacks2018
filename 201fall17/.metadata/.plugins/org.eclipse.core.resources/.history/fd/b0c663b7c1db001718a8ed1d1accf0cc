import java.util.PriorityQueue;

/**
 * Interface that all compression suites must implement. That is they must be
 * able to compress a file and also reverse/decompress that process.
 * 
 * @author Brian Lavallee
 * @since 5 November 2015
 * @author Owen Atrachan
 * @since December 1, 2016
 */
public class HuffProcessor {

	public static final int BITS_PER_WORD = 8;
	public static final int BITS_PER_INT = 32;
	public static final int ALPH_SIZE = (1 << BITS_PER_WORD); // or 256
	public static final int PSEUDO_EOF = ALPH_SIZE;
	public static final int HUFF_NUMBER = 0xface8200;
	public static final int HUFF_TREE = HUFF_NUMBER | 1;
	public static final int HUFF_COUNTS = HUFF_NUMBER | 2;

	public enum Header {
		TREE_HEADER, COUNT_HEADER
	};

	public Header myHeader = Header.TREE_HEADER;

	/**
	 * Compresses a file. Process must be reversible and loss-less.
	 *
	 * @param in
	 *            Buffered bit stream of the file to be compressed.
	 * @param out
	 *            Buffered bit stream writing to the output file.
	 */
	public void compress(BitInputStream in, BitOutputStream out) {
		int[] counts = readForCounts(in);
		HuffNode root = makeTreeFromCounts(counts);
		String[] codings = makeCodingsFromTree(root);
		writeHeader(root, out);
		in.reset();
		writeCompressedBits(in, out, codings);
	}

	public int[] readForCounts(BitInputStream inp) {
		int[] ret = new int[256];
		int current = inp.readBits(BITS_PER_WORD);
		while (current != -1) {
			ret[current] = ret[current] + 1;
			current = inp.readBits(BITS_PER_WORD);
		}
		return ret;
	}

	public void writeHeader(HuffNode root, BitOutputStream outp) {
		outp.writeBits(32, HUFF_TREE);
		writeLeafPath(root, outp);

	}

	public void writeLeafPath(HuffNode root, BitOutputStream outp) {
		if (!isLeaf(root)) {
			outp.writeBits(1, 0);
			writeLeafPath(root.left(), outp);
			writeLeafPath(root.right(), outp);
		} else {
			outp.writeBits(1, 1);
			outp.writeBits(BITS_PER_WORD + 1, root.value());
		}
	}

	public void writeCompressedBits(BitInputStream inp, BitOutputStream outp, String[] encodings) {
		int current = inp.readBits(BITS_PER_WORD);
		while (current > -1) {
			outp.writeBits(encodings[current].length(), Integer.parseInt(encodings[current], 2));
			current = inp.readBits(BITS_PER_WORD);
		}
		outp.writeBits(BITS_PER_WORD + 1, PSEUDO_EOF);
	}

	public HuffNode makeTreeFromCounts(int[] coder) {
		PriorityQueue<HuffNode> pq = new PriorityQueue<HuffNode>();
		pq.add(new HuffNode(PSEUDO_EOF, 1));
		int i = 0;
		for (int a : coder) {
			pq.add(new HuffNode(i, a));
			i++;
		}
		while (pq.size() > 1) {
			HuffNode left = pq.remove();
			HuffNode right = pq.remove();
			HuffNode t = new HuffNode(-1, left.weight() + right.weight(), left, right);
			pq.add(t);
		}
		HuffNode root = pq.remove();
		return root;
	}

	public String[] makeCodingsFromTree(HuffNode a) {

		String[] ret = new String[257];
		for(int i =0; i<ret.length; i++) {
			ret [i] = findLeafPath(a, i, ""); 
		}
		return ret; 

	}

	public String findLeafPath(HuffNode a, int key, String path) {
		if (a.value() == key) {
			return path; 
		} else {
			findLeafPath(a.left(), key, path + "0");
			findLeafPath(a.right(), key, path + "1");
		}
		return null;
	}

	/**
	 * Decompresses a file. Output file must be identical bit-by-bit to the
	 * original.
	 *
	 * @param in
	 *            Buffered bit stream of the file to be decompressed.
	 * @param out
	 *            Buffered bit stream writing to the output file.
	 */
	public void decompress(BitInputStream in, BitOutputStream out) {

		int id = in.readBits(BITS_PER_INT);
		if (id != HUFF_TREE || id == -1) {
			throw new HuffException("not valid");
		}
		HuffNode root = readTreeHeader(in);
		readCompressedBits(in, out, root);

	}

	public HuffNode readTreeHeader(BitInputStream reader) {
		int currentVal = reader.readBits(1); // store the first bit in a temp var

		if (currentVal == 0) {
			HuffNode left = readTreeHeader(reader);
			HuffNode right = readTreeHeader(reader);
			return new HuffNode(0, 0, left, right); // recursively builds a tree based on the input stream
		} else {
			return new HuffNode(reader.readBits(BITS_PER_WORD + 1), 0); // return a leaf with null children
		}

	}

	public boolean isLeaf(HuffNode current) {
		return (current.left() == null && current.right() == null);
	}

	public void readCompressedBits(BitInputStream inp, BitOutputStream outp, HuffNode root) {
		HuffNode current = root;
		while (!isLeaf(current)) {
			if (inp.readBits(1) == -1) {
				throw new HuffException("invalid");
			}
			if (inp.readBits(1) == 0) {
				current = current.left();
			}
			if (inp.readBits(1) == 1) {
				current = current.right();
			}
		}
		if (current.value() == PSEUDO_EOF) {
			return;
		}
		outp.write(current.value());
		current = root;

	}

	public void setHeader(Header header) {
		myHeader = header;
		System.out.println("header set to " + myHeader);
	}
}